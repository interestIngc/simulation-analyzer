{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:02:37.412267Z",
     "start_time": "2024-08-23T06:02:19.149426Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logs_analyzer as analyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "PROTOCOLS = {\"bracha\", \"scalable\", \"witness\"}\n",
    "COMPRESSED = \"compressed\"\n",
    "LOG_DIR = \"logs\"\n",
    "\n",
    "ns = [16, 32, 64, 96, 128, 160, 192, 224, 256]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T06:02:37.417263Z",
     "start_time": "2024-08-23T06:02:37.414303Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_stat(mode=\"stress\"):\n",
    "    statistics = {}\n",
    "\n",
    "    for directory in listdir(LOG_DIR):\n",
    "        if not isdir(join(LOG_DIR, directory)):\n",
    "            continue\n",
    "\n",
    "        ind = directory.find(mode)\n",
    "        if ind == -1:\n",
    "            continue\n",
    "\n",
    "        if mode == \"config\":\n",
    "            splitted_dir = directory[ind:].split(\"_\")\n",
    "            thr = int(splitted_dir[1])\n",
    "            params_str = directory[:ind]\n",
    "        else:\n",
    "            thr = directory[ind:]\n",
    "            params_str = directory[:ind]\n",
    "\n",
    "        params = params_str.split(\"Input\")\n",
    "        protocol = params[0]\n",
    "        n = ns[int(params[1])]\n",
    "\n",
    "        print(directory)\n",
    "\n",
    "        if statistics.get(n) is None:\n",
    "            statistics[n] = {}\n",
    "        if statistics[n].get(protocol) is None:\n",
    "            statistics[n][protocol] = {}\n",
    "\n",
    "        statistics[n][protocol][thr] = \\\n",
    "            analyzer.calculate_stat(\n",
    "                directory=join(LOG_DIR, directory, \"outputs\"),\n",
    "                n=n\n",
    "            )\n",
    "\n",
    "    return statistics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:02:37.427348Z",
     "start_time": "2024-08-23T06:02:37.418665Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rq/sg13x7f91f9b_m60s_21b_540000gn/T/ipykernel_32203/3305928956.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mconfig_statistics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_stat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"config\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/rq/sg13x7f91f9b_m60s_21b_540000gn/T/ipykernel_32203/3595143146.py\u001B[0m in \u001B[0;36mget_stat\u001B[0;34m(mode)\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mstatistics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mdirectory\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLOG_DIR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLOG_DIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdirectory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m             \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'logs'"
     ]
    }
   ],
   "source": [
    "config_statistics = get_stat(mode=\"config\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-08-23T06:02:37.532713Z",
     "start_time": "2024-08-23T06:02:37.430803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PROTOCOL_TO_COLOR = {\n",
    "    \"bracha\": \"blue\",\n",
    "    \"scalable\": \"red\",\n",
    "    \"witness\": \"green\"\n",
    "}\n",
    "\n",
    "def plot(protocol, data):\n",
    "    xs = list(data.keys())\n",
    "    xs.sort()\n",
    "    ys = [data[x] for x in xs]\n",
    "\n",
    "    color = PROTOCOL_TO_COLOR[protocol]\n",
    "    plt.scatter(x=xs, y=ys, color=color)\n",
    "    label = protocol\n",
    "    if protocol == \"bracha\":\n",
    "        label = \"Bracha\"\n",
    "    plt.plot(xs, ys, color=color, label=label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_thr_to_latency(statistics):\n",
    "    throughput_to_latency = {}\n",
    "\n",
    "    for protocol in PROTOCOLS:\n",
    "        throughput_to_latency[protocol] = {}\n",
    "        for n in ns:\n",
    "            if statistics.get(n) is None or statistics[n].get(protocol) is None:\n",
    "                continue\n",
    "\n",
    "            data = []\n",
    "            for rate, stat in statistics[n][protocol].items():\n",
    "                if rate >= 21 or stat[\"transaction_cnt\"] == 0:\n",
    "                    continue\n",
    "\n",
    "                data.append((\n",
    "                    stat[\"avg_throughput\"],\n",
    "                    stat[\"avg_transaction_latency\"]\n",
    "                ))\n",
    "            data = sorted(data, key=lambda pr: pr[0])\n",
    "\n",
    "            adjusted_data = {}\n",
    "            i = 0\n",
    "            while i < len(data):\n",
    "                j = i\n",
    "                sum_latency = 0\n",
    "                while j < len(data) and data[j][0] == data[i][0]:\n",
    "                    sum_latency += data[j][1]\n",
    "                    j += 1\n",
    "\n",
    "                adjusted_data[data[i][0]] = sum_latency / (j - i)\n",
    "\n",
    "                i = j\n",
    "            throughput_to_latency[protocol][n] = adjusted_data\n",
    "\n",
    "    return throughput_to_latency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_throughput_to_latency = build_thr_to_latency(config_statistics)\n",
    "stress_throughput_to_latency = build_thr_to_latency(stress_statistics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_latency_throughput_graph(throughput_to_latency, n):\n",
    "    for protocol in PROTOCOLS:\n",
    "        if throughput_to_latency.get(protocol) is None \\\n",
    "                or throughput_to_latency[protocol].get(n) is None:\n",
    "            continue\n",
    "\n",
    "        data = throughput_to_latency[protocol][n]\n",
    "        plot(protocol=protocol, data=data)\n",
    "\n",
    "    plt.xlabel(xlabel=\"throughput per second\")\n",
    "    plt.ylabel(ylabel=\"latency, s\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"graphs/latency_throughput/{n}.png\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "build_latency_throughput_graph(config_throughput_to_latency, 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_to_label = {\n",
    "    \"avg_transaction_latency\": \"Latency, s\",\n",
    "    \"avg_throughput\": \"Throughput\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_rate_to_metrics(\n",
    "        n,\n",
    "        metrics=\"avg_transaction_latency\",\n",
    "        is_normalized=False\n",
    "):\n",
    "    rate_to_metrics = {}\n",
    "\n",
    "    for protocol in PROTOCOLS:\n",
    "        rate_to_metrics[protocol] = {}\n",
    "\n",
    "    for protocol, protocol_stat in config_statistics[n].items():\n",
    "        curr_rate_to_latency = {}\n",
    "        for rate, stat in protocol_stat.items():\n",
    "            if rate >= 21 or stat[\"transaction_cnt\"] == 0:\n",
    "                continue\n",
    "            curr_rate_to_latency[rate] = stat[metrics]\n",
    "\n",
    "        rate_sorted = list(curr_rate_to_latency.keys())\n",
    "        rate_sorted.sort()\n",
    "\n",
    "        for curr_rate in rate_sorted:\n",
    "            rate_to_metrics[protocol][curr_rate] = curr_rate_to_latency[curr_rate]\n",
    "\n",
    "    if is_normalized:\n",
    "        for rate in rate_to_metrics[\"bracha\"].keys():\n",
    "            for protocol in PROTOCOLS:\n",
    "                if protocol == \"bracha\":\n",
    "                    continue\n",
    "                rate_to_metrics[protocol][rate] /= rate_to_metrics[\"bracha\"][rate]\n",
    "            rate_to_metrics[\"bracha\"][rate] = 1.0\n",
    "\n",
    "    for protocol in PROTOCOLS:\n",
    "        plot(protocol, rate_to_metrics[protocol])\n",
    "\n",
    "    plt.xlabel(xlabel=\"Rate of transactions / 1s\")\n",
    "    plt.ylabel(ylabel=metrics_to_label[metrics])\n",
    "    plt.legend()\n",
    "\n",
    "    parameter = metrics.split(\"_\")[-1]\n",
    "    output_dir = \"normalized\" if is_normalized else \"absolute\"\n",
    "    plt.savefig(f\"graphs/rate_{parameter}/{output_dir}/{n}.png\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for metrics in \"avg_transaction_latency\", \"avg_throughput\":\n",
    "    for is_normalized in True, False:\n",
    "        for n in ns:\n",
    "            build_rate_to_metrics(\n",
    "                n=n,\n",
    "                metrics=metrics,\n",
    "                is_normalized=is_normalized\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_n_metrics(\n",
    "        rate,\n",
    "        metrics=\"avg_transaction_latency\",\n",
    "        is_normalized=False\n",
    "):\n",
    "    protocol_to_stat = {}\n",
    "    for protocol in PROTOCOLS:\n",
    "        protocol_to_stat[protocol] = {}\n",
    "\n",
    "    for n, n_stat in config_statistics.items():\n",
    "        for protocol, protocol_stat in n_stat.items():\n",
    "            protocol_to_stat[protocol][n] = float(protocol_stat[rate][metrics])\n",
    "\n",
    "    if is_normalized:\n",
    "        for n in ns:\n",
    "            for protocol in PROTOCOLS:\n",
    "                if protocol == \"bracha\":\n",
    "                    continue\n",
    "                protocol_to_stat[protocol][n] /= protocol_to_stat[\"bracha\"][n]\n",
    "\n",
    "            protocol_to_stat[\"bracha\"][n] = 1.0\n",
    "\n",
    "    for protocol in PROTOCOLS:\n",
    "        plot(protocol, protocol_to_stat[protocol])\n",
    "\n",
    "    plt.xlabel(xlabel=\"Number of processes\")\n",
    "    plt.ylabel(ylabel=metrics_to_label[metrics])\n",
    "    plt.legend()\n",
    "\n",
    "    parameter = metrics.split(\"_\")[-1]\n",
    "    output_dir = \"normalized\" if is_normalized else \"absolute\"\n",
    "    output_path = f\"graphs/n_{parameter}/{output_dir}\"\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.savefig(f\"{output_path}/{rate}.png\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "build_n_metrics(\n",
    "    rate=16,\n",
    "    metrics=\"avg_transaction_latency\",\n",
    "    is_normalized=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for metrics in \"avg_transaction_latency\", \"avg_throughput\":\n",
    "    for is_normalized in True, False:\n",
    "        build_n_metrics(\n",
    "            rate=16,\n",
    "            metrics=metrics,\n",
    "            is_normalized=is_normalized\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
